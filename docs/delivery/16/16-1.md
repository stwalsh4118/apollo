# [16-1] Embed Schema Type Definitions in Research Prompt

[Back to task list](./tasks.md)

## Description

Replace the example-only "File Format Reference" section in `api/internal/research/prompts/research.md` with explicit type definitions that match the curriculum JSON schema (`schemas/curriculum.json`). The current prompt shows example JSON but never states which fields are required, which are forbidden, or what enum values are allowed. This causes the research agent to invent extra fields (e.g., `slug`, `description` on ConceptTaught) and omit required ones (e.g., `description` on Example).

The updated section must cover every type the agent writes into lesson, module, and topic files — with "NO additional fields allowed" constraints clearly stated for each.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2026-02-20 13:13:28 | Created | N/A | Proposed | Task file created | AI_Agent |

## Requirements

1. Update the "File Format Reference" section in `api/internal/research/prompts/research.md`.
2. For each file type (topic.json, module.json, lesson file), list:
   - All required fields with their types
   - Allowed enum values (difficulty, content section types, exercise types, assessment question types, callout variants, diagram formats)
   - Explicit "NO additional fields allowed" callout per object type
3. Include condensed type definitions for all nested types:
   - `ConceptTaught`: `{id, name, definition, flashcard}` — flashcard: `{front, back}`
   - `ConceptReferenced`: `{id, defined_in}` only
   - `Example`: `{title, description, code, explanation}` — all four required
   - `Exercise`: `{type, title, instructions, success_criteria, hints, environment}` — all six required
   - `ReviewQuestion`: `{question, answer, concepts_tested}`
   - `ContentSection` variants: text `{type, body}`, code `{type, language, code, explanation}` (optional: `title`), callout `{type, variant, body}` (optional: `concept_ref`), diagram `{type, format, source, title}`, table `{type, headers, rows}`, image `{type, url, alt, caption}`
   - `Assessment`: `{questions}` — each question: `{type, question, answer, concepts_tested}`
   - `Prerequisites`: `{essential, helpful, deep_background}` — each item: `{topic_id, reason}`
4. Keep the existing example JSON blocks for reference but augment them with the type constraints.
5. Do NOT change any other sections of the prompt.

## Implementation Plan

1. Read the current "File Format Reference" section (lines 266-358 of `research.md`).
2. Read `schemas/curriculum.json` as the source of truth for all type definitions.
3. Restructure the section to lead with condensed type definitions before the JSON examples.
4. Add a "STRICT SCHEMA RULES" callout block at the top of the section.
5. For each JSON example, annotate required fields and forbidden extras.

## Test Plan

- **Compilation**: No code changes; verify prompt file is valid markdown.
- **Content audit**: All types from `schemas/curriculum.json` `$defs` are represented in the prompt.
- **Known problem areas**: Verify the specific types cited in the PRD problem statement (ConceptTaught, ConceptReferenced, Example, Exercise, ReviewQuestion) all have explicit field lists with "no additional fields" constraints.

## Verification

_To be filled during implementation._

## Files Modified

_To be filled during implementation._
